The contributions to formal methods proposed include:

\begin{itemize}
\item Fundamental contributions to integrating formal specification
languages developed for use in static analysis and theorem proving
with dynamic analysis, producing a common semantics for formal,
static, and dynamic checking of correctness.
\item Enhanced ability of fuzzing and other test generation methods to
make use of information from formal specifications, and integrate
feedback about, e.g., specification coverage into test generation
heuristics.
\item Common semantics and a framework for fuzzing, symbolic execution, SAT/SMT-based
bounded model checking, and explicit-state model checking.
\item Approaches to using feedback from fuzzing to guide bounded or explicit-state model
checking, and vice-versa.
\item Translations from implementation-level specification to
(probabilistic) timed automata models.
\end{itemize}

The contributions to the field include:

\begin{itemize}
\item New development and design methods that focus on
implementation-level specification of correctness of code as a guiding
principle for embedded systems.
\item Tactics and strategies for incorporating the above methods into
legacy efforts, where existing code bases require additional
specification and annotation.
\item Best-practices for using formal, static, and dynamic tools in
debugging known, poorly-understood problems in legacy systems.
\end{itemize}

\subsubsection{Evaluation Approach}
\label{sec:eval}

Because of the focus on practical integration and extension of
existing tools and methods to real-world embedded systems contexts,
much of our evaluation is intimately tied to the work plan where
research is driven by and tied to application to real case studies.
The evaluation approach is therefore fully described in the work plan, below.