While \framac allows, ideally, for proof of correctness of annotated code, in many real-world instances it will be impossible to prove correctness, either because the proof is too hard to construct or because the code is not in fact correct.  While \framac provides some mechanisms for generating possible counterexamples to a proof, and limited test case generation, it is far from ideal in this setting.  A full workflow for verification of realistic systems, therefore, requires a first-class \emph{dynamic} analysis component.  Furthermore, such a component should not limit itself to a single method for generating test cases, as with tools such as KLEE~\cite{KLEE}, Pex~\cite{Pex}, or the test generation tools provided by \framac~\cite{PathCrawler}.  Predicting which test generation methods will discover a fault in code, or simply scale to provide effective exploration of code paths, is notoriously difficult.  Furthermore, most tools are research prototypes and have known bugs that prevent application to some subset of programs.  We therefore aim to provide a \emph{flexible} dynamic front-end that provides a one-stop solution to the problem of dynamic analysis, either to provide confidence in code that cannot be proven correct, or to discover a counterexample showing that the code is not correct.  \deepstate~\cite{DeepState} provides such a front-end.

The research challenge is to translate \acsl-annotated code for use in \framac into a full-featured \deepstate test harness.  This problem can further be broken down into four key-subproblems:

\begin{enumerate}[labelsep=3pt,leftmargin=12pt]
\item The \emph{specification} of correctness must be translated into an executable form.  To some extent, the existence of the \eacsl executable subset of \acsl, and libraries for runtime checking of properties satisfies this condition.  DeepState can support any C/C++ executable method of checking for correctness.  However, because DeepState provides more back-ends, some executable specifications may need to be modified to be efficiently handled when the DeepState back-end is a symbolic execution tool.  Additionally, it is important to instrument the executable code that support specifications in order to make the coverage of the specification itself visible to fuzzer back-ends, such as libFuzzer.  Moreover, DeepState's nature as a test generation tool means that it support constructs, such as ForAll, Minimum, and Maximum, that are not normally available in executable specifications.  Tailoring \eacsl usage for DeepState therefore requires a custom effort, including extending the semantics of ``executable'' specifications and optimizing the implementation for symbolic execution and fuzzing.  Finally, because our domain critically involves timing, we need to implement DeepState handling (and \eacsl representations for) deadlines, and specification of function-level deadlines including arbitrary, specified, ``runtimes'' for code that operates via simulation rather than real hardware, including nondeterministic expression of the timing constraints on calls, and introducing ghost branches that make timing impacts visible to coverage-driven fuzzers.
\item The \emph{assumptions} that control which tests are considered valid must be translated in the same way; normally, \eacsl simply translates these into further assertions (as pre-conditions to check at runtime), but in DeepState, we need to distinguish between {\tt ASSUME} constructs where failure indicates an invalid test and {\tt ASSERT} constructs where failure indicates a failing test.  Additionally, the same optimizations and visibility-to-fuzzer improvements as for the specification must be provided.
\item The inputs to a function must be translated into code controlling the input values that DeepState must generate in a test, including ranges and types.  When input types are simple, this process is straightforward; however, when functions take, e.g., arbitrarily sized arrays or linked lists, or other complex structures, this becomes a problem of constructing a test harness that (1) makes fuzzing and symbolic execution scalable but (2) allows large enough structures to expose subtle bugs.  Moreover, because DeepState supports strategies for input generation, such as forking concrete states for values too complex for symbolic execution using the {\tt Pump} construct, the translation must determine when such strategies are appropriate.
\item In many cases, checking a single function may not be an effective way to detect faults; only a sequence of API calls can expose a problem in a system (e.g., that a function produce a state that causes another function to violate an invariant).  \acsl annotations provide enough information for a fully-automated translation to a harness enabling dynamic analysis in the case of proving properties of a single function, but this is no longer true for groups of functions.  Moreover, even in cases where the violation of a specification can, in theory, be discovered without calling multiple functions, the state space described by the precondition for a function may be too large to explore with a fuzzer or symbolic execution tool.  In such cases, exploring the space described by valid calls of other functions has two benefits:  first, the space described by a sequence of calls may be much smaller, and easier to explore, than the full set of possible input values to a function.  Second, errors in this portion of the input space are more clearly realistic scenarios.  Even if a precondition is not sufficiently restrictive to guarantee correct behavior, if the ``bad'' inputs are never, in practice, generated by the functions that modify system state, the fault may never appear in practice.  In cases where constructing a sufficiently exact precondition is difficult for engineers, such ``in-use'' verification may be the only avenue to system assurance; proof is impossible without a restrictive enough precondition, and dynamic methods may scale very poorly to, e.g., a large unstructured byte buffer such as a hash table.  We propose to let users annotate (in an extension of \acsl) sets of functions to be tested as an API-call-sequence group.  E.g., annotating a set of file system functions ({\tt mkdir}, {\tt rmdir}, {\tt readdir}, etc.) as such a group could allow the automatic generation of a DeepState harness that checks for cases where a sequence of valid function calls can violate a precondition or cause a fault despite preconditions being satisfied.
\end{enumerate}

\begin{figure}[t]
  {\scriptsize
  \begin{code}

void update\_state(struct state\_t *state, uint64\_t bitvector) \{
  ASSUME(valid\_state(state));
  ASSUME(valid\_bv(bitvector));
  ...
\}

void process\_both\_sensor\_readings(struct state\_t *state) \{
  ASSUME(valid\_state(state)); 
  unit64\_t s1\_bv = acquire\_s1(); 
  update\_state(state, s1\_bv); 
  unit64\_t s2\_bv = acquire\_s2(); 
  update\_state(state, s2\_bv);  
\}
  
void process\_one\_sensor\_reading(struct state\_t *state) \{
  ASSUME(valid\_state(state)); 
  unit64\_t s1\_bv = acquire\_s1(); 
  update\_state(state, s1\_bv); 
\}

TEST(SensorReading, UpdateNeverSlow) \{
  struct state\_t state;
  DeepState\_SymbolizeData(\& state, \& state + sizeof(struct state\_t));
  uint64\_t bv = DeepState\_UInt64();
  DeepState\_Timeout([\&] \{update\_state(\&state, bv); \}, MAX\_EXPECTED\_UPDATE\_TIME);
\}

TEST(SensorReading, AvoidCrashes) \{
  struct state\_t state;
  DeepState\_SymbolizeData(\& state, \& state + sizeof(struct state\_t));
  for(int i = 0; i < TEST\_LENGTH; i++) \{
      OneOf([\&] {process\_both\_sensor\_readings(state);},
        [\&] {process\_one\_sensor\_reading(state);});
  \}
\} 
\end{code}
}
  \caption{Portion of a DeepState harness for sensor-reading code}
  \label{fig:assumption}
  \end{figure}

  These goals require significant advances in two areas of dynamic analysis: first, a complete and principled approach to the problem of handling pre-conditions/assumption semantics, and second, an investigation of how to let fuzzers take advantage of the much greater structure involved in property-based testing than in traditional unstructured fuzzing; this includes specification structure, so is inherently tied to the first problem.  Consider the code in Figure~\ref{fig:assumption}.  This defines two different DeepState tests of (largely omitted) software that reads sensor values and incorporates them into a system state structure.  The two tests check two different properties:  {\tt UpdateNeverSlow} ensures that no matter what valid inputs are given to it, updating the sensor is never too slow.  The property is checked, potentially, over \emph{all} valid inputs, not just ones produced by the actual sensor reading code in {\tt acquire\_s1} and {\tt acquire\_s2}.  The second, independent, test, {\tt AvoidCrashes} simply starts the system up in some valid state, and repeatedly either reads both sensors or reads only sensor one.  There is no explicit property here, only the expectation that the system will not crash; tests can be executed using, e.g. LLVM sanitizers to further check for integer overflow, other undefined behavior, and so forth.  Generating such harnesses automatically from \acsl specifications is a significant challenge, but our research agenda also includes solving problems that would appear even if the harness were generated by hand.  First, what is the proper semantics of the {\tt ASSUME} in {\tt update\_state}?  It depends on the test.  In {\tt UpdateNeverSlow}, a fuzzer will often generate an input value that violates the (possibly complex) requirements on valid states and sensor readings.  These invalid inputs should not be flagged as bugs (the default behavior of \eacsl), but instead the test should be abandoned but without indicating that it failed to the fuzzer.  However, in {\tt AvoidCrashes}, since we are not directly generating state values, that is, {\tt update\_state} is not an \emph{entry point} for the test, assumption violations should result in a failed test.  We aim to synthesize code to make assumptions automatically take on the proper semantics during test execution, without the user having to redefine the behavior.  The solution must also encode the difference between a path to search for and a constraint to satisfy for symbolic execution of tests.

  This point about preconditions/{\tt ASSUME} brings up a second point.  Preconditions, when they have an {\tt ASSUME} semantics, are fundamentally different than other branches in code, with respect to fuzzing.  By default, a fuzzer will attempt to explore the behavior of branches in {\tt valid\_state} and {\tt valid\_bv} just as it explores branches in {\tt update\_state} or the {\tt acquire} functions.  However, from the point of view of testing, this is not ideal.  It is often possible to enumerate a vast number of input paths that only define invalid inputs, and so produce very little real testing despite a major computational effort.  A classic example is ``testing'' a file system by producing a huge variety of unmountable file system images, rather than actually executing any POSIX operations at all~\cite{CFV08,AMAI}.  DeepState ``knows'' which branches are pre-conditions, and so can help a fuzzer avoid this problem.  In some fuzzers, this means prioritizing inputs to mutate based on whether they execute any code other than validity checks; but in ``smart fuzzers'' such as Angora~\cite{angora} and Eclipser~\cite{eclipser} that perform lightweight constraint-solving to cover branches, the process can be even more sophisticated.  We have begun discussions with the Eclipser team, and they confirm that identifying precondition code and devising suitable heuristics to handle it (e.g., never solve for a negation of a validity check) should improve Eclipser's performance in property-based fuzzing.  Devising effective heuristics to tune both ``classic'' mutation fuzzers and concolic gray-box fuzzers promises to improve test generation not only in the context of our workflow, but in general.

This effort also connects to a second fuzzing research thrust: making specification elements that do not correspond to simple code coverage visible to a fuzzer.  In this example, consider the {\tt DeepState\_Timeout} check (note that this itself is functionality we will develop as part of handing timing constraints in \framac and DeepState).  Unless we break down the timing analysis explicitly, coverage-driven fuzzers cannot distinguish an execution that is very slow (close to violating the constraint) from one that has the minimum execution time possible.  We propose to make timing of such specified events visible to a fuzzer, by modifying coverage bitvectors to incorporate bucketing of execution time.  Once we add such novel coverage measures, and introduce distinctions between coverage classes (as with preconditions), we will research how to balance competing priorities in more complex notions of coverage.  We assume that as we investigate real world examples, further challenging research problems in property-based fuzzing will arise and require improving fuzzer science and art.

% Additionally, in some cases, checking a single function may not be an effective way to detect faults; only a sequence of API calls can expose a problem in a system (e.g., that a function produce a state that causes another function to violate an invariant).  \acsl annotations provide enough information for a fully-automated translation to a harness enabling dynamic analysis in the case of proving properties of a single function, but this is no longer true for groups of functions.  Moreover, even in cases where the violation of a specification can, in theory, be discovered without calling multiple functions, the state space described by the precondition for a function may be too large to explore with a fuzzer or symbolic execution tool.  In such cases, exploring the space described by valid calls of other functions has two benefits:  first, the space described by a sequence of calls may be much smaller, and easier to explore, than the full set of possible input values to a function.  Second, errors in this portion of the input space are more clearly realistic scenarios.  Even if a precondition is not sufficiently restrictive to guarantee correct behavior, if the ``bad'' inputs are never, in practice, generated by the functions that modify system state, the fault may never appear in practice.  In cases where constructing a sufficiently exact precondition is difficult for engineers, such ``in-use'' verification may be the only avenue to system assurance; proof is impossible without a restrictive enough precondition, and dynamic methods may scale very poorly to, e.g., a large unstructured byte buffer such as a hash table.

% In principle, of course, users can write a new function (a kind of ``ghost function'' not really executed---in practice, a test harness) expressing the desired mix of API calls that preserve an invariant; however, this is a serious burden on a user, and users are likely to make errors in this task~\cite{CFV08,AMAI,scriptstospecs,groce2015verified,groce2018verified}; we instead propose to let users annotate (in an extension of \acsl) sets of functions to be tested as an API-call-sequence group.  E.g., annotating a set of file system functions ({\tt mkdir}, {\tt rmdir}, {\tt readdir}, etc.) as such a group could allow the automatic generation of a DeepState harness that checks for cases where a sequence of valid function calls can violate a precondition or cause a fault despite preconditions being satisfied.

