%\notetruong{We should update Figure 1 and relate this section to the steps in Figure 1.}
As discussed above, a full workflow for verification of realistic systems requires a first-class, flexible, \emph{dynamic} analysis component, such as \deepstate~\cite{DeepState}.  The research challenge is to translate \acsl-annotated code for use in \framac into a full-featured \deepstate test harness:

\begin{enumerate}[labelsep=3pt,leftmargin=12pt]
\item The \emph{specification} of correctness must be translated into an executable form.  To some extent, the existence of the \eacsl executable subset of \acsl, and libraries for runtime checking of properties satisfies this condition.  DeepState can support any C/C++ executable method of checking for correctness.  However, some executable specifications need to be modified to be efficiently handled when the DeepState back-end is a symbolic execution tool.  DeepState's nature as a test generation tool means that it supports constructs, such as {\tt Minimum}, {\tt Maximum}, and {\tt Pump}, not usually available in executable specifications.  Tailoring \eacsl usage for DeepState therefore requires a custom effort, including extending the semantics of executable specifications and optimizing the implementation for symbolic execution and fuzzing.  Finally, because our domain critically involves timing, we need to implement DeepState handling of (and \eacsl representations for) deadlines, and specification of function-level deadlines including arbitrary, specified, ``runtimes'' for code that operates via simulation rather than real hardware (or in symbolic execution).
\item The \emph{assumptions} that control which tests are considered valid must be translated in the same way; normally, \eacsl simply translates these into further assertions (as pre-conditions to check at runtime), but in DeepState, we need to distinguish between {\tt ASSUME} constructs where failure indicates an invalid test and {\tt ASSERT} constructs where failure indicates a failing test.  
\item The inputs to a function must be translated into code controlling the input values that DeepState provides, including ranges and types.  When input types are simple, this process is straightforward; however, when functions take, e.g., arbitrarily sized arrays, linked lists, or other complex structures, this becomes a problem of constructing a test harness that (1) makes fuzzing and symbolic execution scalable but (2) uses large enough structures to expose subtle bugs.  Moreover, because DeepState supports strategies for input generation, such as forking concrete states for values too complex for symbolic execution using the {\tt Pump} construct, the translation must determine when such strategies are appropriate, and apply them.
\item In many cases, checking a single function may not be an effective way to detect faults; only a sequence of API calls can expose a problem in a system (e.g., that a function produce a state that causes another function to violate an invariant).  \acsl annotations provide enough information for a fully-automated translation to a harness enabling dynamic analysis in the case of proving properties of a single function, but not for groups of functions.  Moreover, even in cases where the violation of a specification can, in theory, be discovered without calling multiple functions, the state space may be too large to explore with a fuzzer or symbolic execution tool.  In such cases, exploring only states produced by valid call sequences has two benefits:  first, the space itself may be much smaller, and easier to explore, than the full set of possible input values.  Second, errors in this part of the input space are more important.  Even if a precondition is not sufficiently restrictive to guarantee correct behavior, if the ``bad'' inputs are never, in practice, generated by the functions that modify system state, the fault may not matter.  In cases where constructing a sufficiently exact precondition is difficult for engineers, such ``in-use'' verification may be the only avenue to system assurance; proof is impossible without a restrictive enough precondition, and dynamic methods may scale very poorly to, e.g., a large unstructured byte buffer such as a hash table.  We propose to let users annotate (in an extension of \acsl) sets of functions to be tested as an API-call-sequence group, extending recent work exploring this concept~\cite{blatter2018static,MetAcsl}.  E.g., annotating a set of file system functions ({\tt mkdir}, {\tt rmdir}, {\tt readdir}, etc.) as such a group could allow the automatic generation of a DeepState harness that checks for cases where a sequence of valid function calls can violate a precondition or cause a fault despite preconditions being satisfied.
\end{enumerate}

\begin{figure}[t]
  \begin{subfigure}{0.5\columnwidth}
  {\scriptsize
  \begin{code}

void update\_state(struct state\_t *s, uint64\_t bv) \{
  ASSUME(valid\_state(s));
  ASSUME(valid\_bv(bv));
  ...
\}

void process\_both\_sensor\_readings(struct state\_t *s) \{
  ASSUME(valid\_state(s)); 
  unit64\_t s1\_bv = acquire\_s1(); 
  update\_state(s, s1\_bv); 
  unit64\_t s2\_bv = acquire\_s2(); 
  update\_state(s, s2\_bv);  
\}
  
void process\_one\_sensor\_reading(struct state\_t *s) \{
  ASSUME(valid\_state(s)); 
  unit64\_t s1\_bv = acquire\_s1(); 
  update\_state(s, s1\_bv); 
\}
\end{code}
}
\end{subfigure}
\begin{subfigure}{0.5\columnwidth}
{\scriptsize
\begin{code}
struct state\_t *NewState() \{
  return
    DeepState\_Malloc(sizeof(struct state\_t));   
\}
    
TEST(SensorReading, UpdateNeverSlow) \{
  struct state\_t *s = NewState();
  uint64\_t bv = DeepState\_UInt64();
  DeepState\_Timeout(
    [\&]\{update\_state(s, bv);\},
    MAX\_EXPECTED\_UPDATE\_TIME);
\}

TEST(SensorReading, AvoidCrashes) \{
  struct state\_t *s = NewState();
  for(int i = 0; i < TEST\_LENGTH; i++) \{
    OneOf(
        [\&]\{process\_both\_sensor\_readings(s);\},
        [\&]\{process\_one\_sensor\_reading(s);\});
  \}
\} 
\end{code}
}
\end{subfigure}
  \caption{Sensor reading code and DeepState test harness}
  \label{fig:assumption}
  \end{figure}

  These goals require significant advances in two areas of dynamic analysis: first, a complete and principled approach to the problem of handling pre-conditions/assumption semantics, and second, an investigation of how to let fuzzers take advantage of the significant additional structure provided by property-based testing, including such assumptions.  Consider the code in Figure~\ref{fig:assumption}.  This defines two different tests of software that reads sensor values and incorporates them into a system state.  The two tests check two different properties:  {\tt UpdateNeverSlow} ensures that updating the sensor is never too slow.  It is checked, potentially, over \emph{all} valid inputs, not just ones produced by the actual sensor reading code in {\tt acquire\_s1} and {\tt acquire\_s2}.  The second test, {\tt AvoidCrashes} starts the system up in some valid state, and repeatedly either reads both sensors or only sensor one.  There is no explicit property, only the expectation that the system will not crash; tests can be executed using LLVM sanitizers to check for integer overflow and other undefined behavior.  Generating such harnesses automatically from \acsl specifications is a significant challenge, but our research agenda also includes solving problems that would appear even for manual harnesses.  For example, what is the proper semantics of the {\tt ASSUME} in {\tt update\_state}?  It depends on the test.  In {\tt UpdateNeverSlow}, a fuzzer will often generate an input value that violates the (possibly complex) requirements on valid states and sensor readings.  These invalid inputs should not be flagged as bugs (the default behavior of \eacsl), but instead the test should be abandoned without indicating that it failed.  However, in {\tt AvoidCrashes}, since we are not directly generating state values, that is, {\tt update\_state} is not an \emph{entry point} for the test, assumption violations should result in failed tests.  We aim to synthesize code to make assumptions automatically take on the proper semantics during test execution (including symbolic execution using constraint solvers), without the user having to redefine the behavior. 

  This point about preconditions/{\tt ASSUME} brings up a second point.  Preconditions, when they have an {\tt ASSUME} semantics, are fundamentally different than other branches in code.  A fuzzer will attempt to explore the behavior of branches in {\tt valid\_state} and {\tt valid\_bv} just as it explores branches in {\tt update\_state} or {\tt acquire}.  However, it is often possible to enumerate a vast number of paths that differentiate only invalid inputs, and so produce very little real testing.  A classic example is ``testing'' a file system by producing a huge variety of unmountable file system images, rather than actually executing any POSIX operations at all~\cite{CFV08,AMAI}.  DeepState knows which branches are pre-conditions, and so can help avoid this problem.  In some fuzzers, this means prioritizing inputs to mutate based on whether they execute any code other than validity checks; but in fuzzers such as Angora~\cite{angora} and Eclipser~\cite{eclipser} that use lightweight constraint-solving to cover branches, the process can be more sophisticated.  We have begun discussions with the Eclipser team, and they confirm that identifying precondition code and devising suitable heuristics to handle it (e.g., never solve for a negation of a passed check) should improve performance.  Devising effective heuristics to tune both ``classic'' mutation fuzzers and concolic gray-box fuzzers promises to improve test generation not only in our context, but in general.  Fuzzing of individual functions or sets of functions is a highly promising area: most fuzzing is applied at the whole-program level, where learning to produce interesting inputs can be an overwhelming problem.  By focusing on a middle-ground between unit testing and whole-program fuzzing, that is by using modern fuzzer technology to drive property-driven testing, the problem may be more tractable.  Prioritizing paths that include more behavior than just input validation is an explicit goal of, e.g., AFLFast~\cite{aflfast}, but it must work with an implicit definition based on path frequencies, while we have access to more precise data.  Given the possible complexity of a state validity check, there may be hard-to-reach---but fundamentally uninteresting---ways to create invalid input; AFLFast will prioritize such paths, while our approach will (correctly) avoid them.

This effort also connects to a second fuzzing research thrust: making specification elements that do not correspond to simple code coverage visible to a fuzzer.  In this example, consider the {\tt DeepState\_Timeout} check (note that this itself is functionality we will develop as part of handing timing constraints in \framac and DeepState).  Unless we break down the timing analysis explicitly using a set of conditional branches, coverage-driven fuzzers cannot distinguish an execution that is very slow (close to violating the constraint) from one that has the minimum execution time possible.  We propose to make timing of such specified events visible to a fuzzer, by modifying coverage bit-vectors to incorporate bucketing of execution time.  Once we add such novel coverage measures, and introduce distinctions between coverage classes (as with preconditions), we will research how to balance competing priorities in more complex notions of coverage.  In addition to implicit execution properties such as timing, this effort can apply to coverage of data structures, which is also a critical problem in fuzzing data-driven code such as machine-learning algorithms, where much of the behavior is implicit in, e.g., the route taken through a forest of decision trees.  We assume that as we investigate real world examples, further challenging research problems in property-based fuzzing will arise and require improving fuzzer science and art.  In essence, this proposal aims to extend the work, including AFLFast~\cite{aflfast}, FairFuzz~\cite{lemieux2018fairfuzz}, VUzzer~\cite{vuzzer}, and other efforts~\cite{zhao2019send,aschermann2019redqueen}, that prioritizes certain program paths over others in an intelligent way, by specializing that set of approaches to the case of property-based testing with a stronger specification and understanding of interacting functions and data structures.

% Additionally, in some cases, checking a single function may not be an effective way to detect faults; only a sequence of API calls can expose a problem in a system (e.g., that a function produce a state that causes another function to violate an invariant).  \acsl annotations provide enough information for a fully-automated translation to a harness enabling dynamic analysis in the case of proving properties of a single function, but this is no longer true for groups of functions.  Moreover, even in cases where the violation of a specification can, in theory, be discovered without calling multiple functions, the state space described by the precondition for a function may be too large to explore with a fuzzer or symbolic execution tool.  In such cases, exploring the space described by valid calls of other functions has two benefits:  first, the space described by a sequence of calls may be much smaller, and easier to explore, than the full set of possible input values to a function.  Second, errors in this portion of the input space are more clearly realistic scenarios.  Even if a precondition is not sufficiently restrictive to guarantee correct behavior, if the ``bad'' inputs are never, in practice, generated by the functions that modify system state, the fault may never appear in practice.  In cases where constructing a sufficiently exact precondition is difficult for engineers, such ``in-use'' verification may be the only avenue to system assurance; proof is impossible without a restrictive enough precondition, and dynamic methods may scale very poorly to, e.g., a large unstructured byte buffer such as a hash table.

% In principle, of course, users can write a new function (a kind of ``ghost function'' not really executed---in practice, a test harness) expressing the desired mix of API calls that preserve an invariant; however, this is a serious burden on a user, and users are likely to make errors in this task~\cite{CFV08,AMAI,scriptstospecs,groce2015verified,groce2018verified}; we instead propose to let users annotate (in an extension of \acsl) sets of functions to be tested as an API-call-sequence group.  E.g., annotating a set of file system functions ({\tt mkdir}, {\tt rmdir}, {\tt readdir}, etc.) as such a group could allow the automatic generation of a DeepState harness that checks for cases where a sequence of valid function calls can violate a precondition or cause a fault despite preconditions being satisfied.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
