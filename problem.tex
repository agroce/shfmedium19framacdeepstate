The core problem we aim to address in this proposal is that \emph{use of formal modeling, advanced static analysis, and advanced dynamic analysis tools in C and C++} for verification and validation, especially on critical, timing-dependent, embedded and cyber-physical systems, is prohibitively difficult and lacks sufficient synergy for effective application in real-world projects.  This limitation applies even to systems built in an academic research context, unless the context is specifically that of using such systems (that is, unless the research is primarily \emph{about} methods for verifying and testing systems, rather than work on an embdeded system for its own sake).  Furthermore, even when use of these techniques to ensure correctness, reliability, or security \emph{is} a focus of the project, such use is almost always limited to one type of effort---model checking, theorem proving, or dynamic analysis (e.g., automated test case generation).  A major cause for this difficulty is the \emph{lack of synergy} between these related efforts, the failure of effort in one context to transfer to another context.  In short:

\begin{itemize}[labelsep=3pt,leftmargin=12pt]
\item Learning to use a formal modeling language and tool, such as \uppaal~\cite{uppaal}, \prism~\cite{KNP2011:CAV}, or \spin~\cite{SPIN}, provides help in discovering defects in a high-level, abstract formulation of a model or protocol, but seldom helps with implementation-level problems not directly modeled in the formalism.
\item Many static analysis tools are primarily ``bug detectors'' (e.g, Coverity or CodeSonar), whose output is essentially limited to a list of possible problems.  These tools, however, seldom provide any means for producing tests that can help distinguish false positives from real problems with the code.
\item More powerful static analysis tools, such as \framac~\cite{KKP2015:FAC}, provide proofs of correctness for limited aspects of a system, and a rich specification and annotation language.  There is no connection between this annotation and either formal modeling or test generation using anything other than a concolic tool that is limited in functionality and scalability.
\item There are a large variety of automated test generation tools; however, again, effort spent in learning one of these tools only partially applies to learning a different tool.  Furthermore, many of the most powerful such tools (e.g., AFL ~\cite{aflfuzz}) are specialized to the problem of finding memory safety vulnerabilities, and provide no support for  the kind of testing needed for  other types of faults in e.g., communication protocols used in distributed embedded systems.  Finally, none of these tools significantly leverage specification and verification effort from formal modeling or advanced static analysis.
\end{itemize}

Consider the case of an engineer working on a custom, low-energy consumption, communication protocol for use in a distributed system consisting of low-power sensors and actuators.  If the engineer builds a formal model of the protocol, she will discover that this extensive effort provides no help, other than an improved concept of the system, in proving the correctness of the actual implementation, even if the property to be proved exists in the model.  If the engineer begins instead by building an automated test generation harness she again discovers that despite having spent considerable time expressing pre-conditions and post-conditions for various functions in the implementation, to guide test generation, the work must be duplicated when she decides to try to formally prove the correctness of core functionality.  Had she begun with the proofs, again, logically related (or even equivalent) information would have to be re-expressed, in a different language, to perform test generation.  Not only must our engineer learn three tools, but effort spent in using one tool almost never carries over to another approach.  In almost all cases, there is simply not enough time or energy available to make use of the full spectrum of available technology.  In practice, \emph{no advanced correctness technology may be used at all.}  After all, it is hard to predict which technology will have the greatest payoff, or even work at all, so perhaps it is best to just put more effort into manual testing.

\subsection{Proposed Solution}

While allowing efforts from any form of formal or automated verification or validation attempt to maximally carry over to other forms (i.e., formal models to code annotations for static analysis, code annotations to test harnesses, test harnesses to code annotations, test harnesses to formal models, formal models to test harnesses, and code annotations to formal models) is the ideal goal, simply making it possible to follow \emph{one} critical path to combine methods is feasible given current technologies in the sub-domains (formal modeling, static analysis, and dynamic analysis) and a set of specific advances in bridging the gap between the technologies.

Thus the question becomes:  which path is most important to realize?  Our approach is based in the reality of the embedded systems domain, where, while formal modeling is sometimes used, there is, in real-world efforts, \emph{always} an implementation.  The most basic obstacle to the adoption of formal methods in embedded systems work is that if the realities of development preclude extensive formal efforts, and there is only the usual informal design effort or adaptation of an existing implementation, formal methods are often simply inapplicable.  By focusing on adding annotations to the actual implementation code, and exploiting those annotations to enable a set of potentially bug-finding or correctness-proving analyses, we promise to \emph{always} give embedded systems engineers a reasonable payoff for their formal specification effort, often in a form (failing tests) that always provides practical benefit and can never be dismissed in critical embedded systems efforts.

This project therefore proposes to make it possible to introduce specifications into implementation code that can be directly checked using sophisticated automated test generation strategies, including symbolic execution, advanced fuzzing, explicit-state model checking, and SAT/SMT-based bounded model checking.   Furthermore, these specifications can be directly exported to form the basis for formal models using, e.g., timed automata.  In the long run, to benefit those developers who are more open to formal methods already, we hope that these annotations can be imported from a timed automata representation, but we begin where most embedded systems developers are, now, not where we hope they may be in some indeterminate future.
To further improve the value of our approach, we focus on integrating static and dynamic analysis tools that are, themselves, frameworks/front-ends allowing application of multiple approaches.  Our intellectual committment is to enabling \emph{a maximum diversity of analysis methods} with \emph{a minimum of specification and tool-learning effort}, to make formal methods attractive \emph{simply because of their expected cost-benefit ratio}.

This project is specifically focused on communication protocol implementations in embedded systems where timing is critical to the modeling of behavior, but we expect that our solution will generalize to other critical C and C++ systems development scenarios.  Note that we target the common, hard, case where our approach will be applied to systems with partial or complete existing implementations: typical legacy embedded C code.  We expect developers to learn new tools, but not new programming paradigms or languages.  The contribution to embedded systems design therefore is not a radical reworking of development methods, which, like many formal methods efforts in the past, is unlikely to achieve widespread adoption, but the introduction of, essentially, \emph{an advanced form of unit testing, with more powerful methods for specifying ``testing and verification problems'' and more powerful, low-effort ways to try to solve those problems.}  The end-result for embedded systems engineers will be an approach to development that works with legacy code, and does not require a fundamental shift in approach, but will \emph{support} early adoption of formal modeling as, e.g., timed automata, if present, and, critically, will allow engineers to express the correctness properties in a full-featured way directly in code, while enabling use of a variety of methods to check those properties.  This will modify development, in that design-for-testability and design-for-verifiability will become second nature.  Just as the introduction of the possibility to express \emph{and check} strong typing constraints changed Python development practices for high-value projects, the introduction of the possibility to express \emph{and check} correctness properties will change embedded system development.

\noindent\fbox{%
    \parbox{\textwidth}{%
\bf Summary:  This project is based on the following core ideas:
  \begin{enumerate}
  \item The primary obstacle to adoption of formal methods approaches in embedded systems development is not a lack of relevant methods and tools.
  \item In particular, there are methods and tools that apply to the \emph{implementation} of embedded systems in C and C++; every embedded software system requires an implementation.
  \item However, learning and using any one of these tools may or may not ``pay off'' and the effort spent is only of limited application when applying another tool.
  \item Therefore, to improve embedded systems development via formal methods we need:
    \begin{enumerate} \item an \emph{implementation-focused} \emph{common framework} for applying methods and tools and
    \item a focus on \emph{practically-inspired} improvements to the methods and tools encompassed by that framework enabling them to work better \emph{within the framework}.
      \end{enumerate}
  \end{enumerate}
}
}

\subsubsection{PI Qualifications}

See the collaboration plan for an extensive examination of PI Qualifications; in brief, PI Groce has extensive history with formal methods, testing and verification tool development, and practical application to real-world systems, including NASA Mars missions.  Co-PI Ngheim is an expert in control and autonomy for embedded robotics, including application of formal methods to such systems.  Co-PI Flikkema has extensive experience on complex deployed real-world embeddes systems and networks used in critical environmental and ecological science applications.

