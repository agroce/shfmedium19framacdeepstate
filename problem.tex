The core problem we aim to address in this proposal is that \emph{use of formal modeling, advanced static analysis, and advanced dynamic analysis} for verification and validation, especially on critical embedded systems, is prohibitively difficult and lacks sufficient synergy for cost-effective application.  This is true even of systems built in an academic research context: that is, unless the research is primarily \emph{about} methods for verifying and testing systems, rather than work on an embdeded system for its own sake, these methods are hard to apply.  Furthermore, even when use of these techniques to ensure correctness, reliability, or security \emph{is} a focus of the project, such use is almost always limited to one type of effort---model checking, theorem proving, or automated test generation.  A major cause for this difficulty is the \emph{lack of synergy} between these related efforts, the failure of effort in one context to transfer to another context.  In short:

\begin{itemize}[labelsep=3pt,leftmargin=12pt]
\item Learning to use a formal modeling language and tool, such as \uppaal~\cite{uppaal}, \prism~\cite{KNP2011:CAV}, or \spin~\cite{SPIN}, provides help in discovering defects in a high-level, abstract formulation of a model or protocol, but seldom helps with implementation-level problems not directly modeled in the formalism.
\item Many static analysis tools are primarily ``bug detectors'' (e.g, Coverity or CodeSonar), whose output is essentially limited to a list of possible problems; devising test inputs to reject false positives is hard.
\item More powerful static analysis tools, such as \framac~\cite{KKP2015:FAC}, provide proofs of correctness for limited aspects of a system, and a rich specification and annotation language.  However, there is little or no connection between this annotation and either formal modeling or state-of-the-art test generation.
\item There are a large variety of automated test generation tools; however, effort spent learning one tool only partially transfers to another tool.  Furthermore, many of the most powerful such tools (e.g., AFL~\cite{aflfuzz}) are specialized to the problem of finding \emph{crashes}, and do not leverage  other types of specification efforts \emph{at all}.
\end{itemize}

Consider the case of an embedded systems engineer working on a custom, low-energy consumption, communication protocol for use in a network of low-power sensors and actuators.  If she builds a formal model of the protocol, she will likely discover that this extensive effort provides no help, other than an improved concept of the system, in proving the correctness of her \emph{implementation}.  If the engineer begins instead by building an automated test generation harness she will find that, despite having spent considerable time expressing pre-conditions and post-conditions for various functions in the implementation, the work must be duplicated when she decides to try to formally prove the correctness of core functionality.  Had she begun with the proofs, again, logically related (or even equivalent) information would have to be re-expressed, in a different language, to perform test generation.  Not only must our engineer learn three tools, but effort spent in using one tool almost never carries over to another approach.  In almost all cases, there is simply not enough time or energy available to make use of the full spectrum of available technology.  In practice, \emph{no advanced correctness technology may be used at all.}  After all, it is hard to predict which one(s) will have the greatest payoff, or even work at all, so perhaps it is best to just put more effort into manual testing.

\subsection{Proposed Solution}

While allowing efforts from any form of formal or automated verification or validation attempt to carry over to other forms (i.e., formal models to code annotations for static analysis, code annotations to test harnesses, test harnesses to code annotations, test harnesses to formal models, formal models to test harnesses, and code annotations to formal models) is the ideal goal, simply making it possible to follow \emph{one} critical path to combine methods is feasible given current technologies in the sub-domains (formal modeling, static analysis, and dynamic analysis) and a set of specific advances in bridging the gap between the technologies.

Which path is most important to realize?  Our approach is based in the reality of the embedded systems domain, where, while formal modeling is sometimes used, there is, in real-world efforts, \emph{always} an implementation.  The most basic obstacle to the adoption of formal methods in embedded systems work is that if there is only the usual informal design effort or adaptation of a legacy implementation, formal methods are often simply inapplicable.  By focusing on \emph{adding annotations to implementation code}, and exploiting those annotations to enable a set of potentially bug-finding or correctness-proving analyses, we promise to \emph{always} give embedded systems engineers a reasonable payoff, often in the form of \emph{tests showing real bugs}.

This project therefore proposes to make it possible to introduce specifications into implementation code that can be directly checked using sophisticated automated test generation strategies, including symbolic execution, advanced fuzzing, explicit-state model checking, and SAT/SMT-based bounded model checking.   Furthermore, these specifications can be directly exported to form the basis for formal models using, e.g., timed automata.  In the long run, to benefit those developers who are more open to formal methods already, we hope that these annotations can be imported from a timed automata representation, but we begin where most embedded systems developers are, now, not where we hope they may be, someday.
We additionally focus on using frameworks/front-ends allowing application of multiple approaches.  Our committment is to enabling \emph{a maximum diversity of analysis methods} with \emph{a minimum of specification and tool-learning effort}, to make formal methods attractive \emph{simply because of their expected cost-benefit ratio}.

This project is specifically focused on communication protocol implementations in embedded systems where timing is critical to the modeling of behavior, but we expect that our solution will generalize to other critical low-level development efforts because we target the common, hard, case where our approach will be applied to systems with partial or complete existing implementations: typical legacy embedded C code.  We expect developers to learn new tools, but not new programming paradigms or languages.  The proposed contribution to embedded systems design is not a radical reworking of development methods, which, like many formal methods efforts in the past, would be unlikely to achieve widespread adoption, but the introduction of \emph{an advanced form of unit testing, that works with legacy code, with more powerful methods for specification and checking of correctness.}  This will modify development, in that design-for-testability and design-for-verifiability will become second nature---just as the introduction of the possibility to express \emph{and check} strong typing constraints changed Python development practices for projects where reliability and correctness really mattered.  This project is therefore based on the following core ideas:

\noindent\fbox{%
  \bf
    \parbox{0.972\textwidth}{%
  \begin{enumerate}
  \item The primary obstacle to adoption of formal methods approaches in embedded systems development is not a lack of relevant methods and tools.
  \item In particular, there are methods and tools that apply to the \emph{implementation} of embedded systems in C and C++; every embedded software system requires an implementation.
  \item However, learning and using any one of these tools may or may not ``pay off'' and the effort spent is only of limited application when applying another tool.
  \item Therefore, to improve embedded systems development via formal methods we need:
    \begin{enumerate} \item an \emph{implementation-focused} \emph{common framework} for applying methods and tools and
    \item a focus on \emph{practically-inspired} improvements to the methods and tools thus encompassed.
      \end{enumerate}
  \end{enumerate}
}
}

\subsubsection{PI Qualifications}

See the collaboration plan for an extensive examination of PI Qualifications; in brief, PI Groce has extensive history with formal methods and testing tool development, and practical application to real-world embedded systems.  Co-PI Nghiem is an expert in control and autonomy for robotics, including use of formal methods, and   Co-PI Flikkema has extensive experience with deployed real-world embedded systems and networks.
